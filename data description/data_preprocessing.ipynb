{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The path to my training dataset\n",
    "data_dir = 'C:\\\\Users\\\\VANSH GARG\\\\.cache\\\\kagglehub\\\\datasets\\\\awsaf49\\\\brats2020-training-data\\\\versions\\\\3\\\\BraTS2020_training_data\\\\content\\\\data'\n",
    "h5_files = [f for f in sorted(os.listdir(data_dir)) if f.endswith('.h5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The below function is a generalised function with extracts the data from the HDF5 files which exists in the form of 2D slices. The function then \n",
    "stacks the slices of the same volume in sequential order and then stores the new 4 Dimensional array into a new HDF5 file. I named brain_tumor_data4.h5\n",
    "Along the way the function also preprocesses the data as is required.'''\n",
    "def data_generation(files):\n",
    "    data_sorted=[0]*(155*369)\n",
    "    for i in files:\n",
    "        L=i.split(\"_\")\n",
    "        k=int(L[-1].split(\".\")[0])\n",
    "        n=int(L[1])\n",
    "        data_sorted[(155*(n-1))+k]=i\n",
    "    #Data_sorted contains proper sorted order of the slices but in the form of a list \n",
    "    img_slices=[]\n",
    "    msk_slices=[]\n",
    "    #Created two slices to store the 3 layer(depth) in it\n",
    "    j=0\n",
    "    with h5py.File(\"brain_tumor_data4.h5\", \"w\") as hf:\n",
    "        #Created two HDF5 data files which is 5 dimensional in nature and stores value in float16 format\n",
    "        hf.create_dataset(\"X\", shape=(369, 128, 128, 32, 4), dtype='float16', chunks=True)\n",
    "        hf.create_dataset(\"Y\", shape=(369, 128, 128, 32), dtype='float16', chunks=True)\n",
    "        for k,i in enumerate(data_sorted):\n",
    "            j+=1\n",
    "            file=os.path.join(data_dir,i)\n",
    "            with h5py.File(file, 'r') as f:\n",
    "                #Normalising and reducing the size of image and mask data files\n",
    "                image_data=np.array(f['image'],dtype='float16')\n",
    "                image_data = (image_data - np.min(image_data)) / (np.max(image_data) - np.min(image_data) + 1e-6)\n",
    "                mask_data=np.array(f['mask'],dtype='float16')\n",
    "                mask_data = np.mean(mask_data, axis=-1) #Taking the mean of the mask file along it's channels\n",
    "                mask_data = (mask_data - np.min(mask_data)) / (np.max(mask_data) - np.min(mask_data) + 1e-6)\n",
    "                if np.max(mask_data) > 0: #This condition allows only data files with a tumor region in it to be appeneded. This ensures that as much information is retained as possible. To properly train the model.\n",
    "                    img_slices.append(image_data)\n",
    "                    msk_slices.append(mask_data)\n",
    "                if j==155:\n",
    "                    img_voxel=np.stack(img_slices,axis=2)  #Stacking the image and mask slices into the 3 axis of image voxels\n",
    "                    msk_voxel=np.stack(msk_slices,axis=2)  \n",
    "                    img_voxel= resize(img_voxel,(128,128,32,4),preserve_range=True,anti_aliasing=True) #Resizing the voxels into a uniform size to ensure uniformity. Used features such as anti_aliasing and preserve_range.\n",
    "                    msk_voxel= resize(msk_voxel,(128,128,32),preserve_range=True,anti_aliasing=True)\n",
    "                    hf[\"X\"][(k//155)] = img_voxel #This line makes sure to properly index my data and make it sequential.\n",
    "                    hf[\"Y\"][(k//155)] = msk_voxel\n",
    "                    img_slices=[]\n",
    "                    msk_slices=[]\n",
    "                    j=0\n",
    "                    continue    \n",
    "data_generation(h5_files)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
